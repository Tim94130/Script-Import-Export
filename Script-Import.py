# Importation des biblioth√®ques n√©cessaires
import pandas as pd
from tkinter import Tk, filedialog
import os
import re
import json
import requests
from time import sleep
import unicodedata
from collections import defaultdict
from rapidfuzz import process, fuzz  # Si n√©cessaireimport csv
import csv
import MySQLdb


# D√©finitions globales pour la d√©tection des couleurs
adjectifs_ignores = [
    "dark", "light", "pale", "deep", "bright", "medium",
    "fonce", "fonc√©", "clair", "p√¢le", "flashy", "fluorescent"
]

couleurs_base = [
    "white", "black", "brown", "blue", "red", "pink", "green", 
    "grey", "gray", "yellow", "orange", "purple", "violet",
    "beige", "gold", "silver", "taupe", "cyan", "magenta",
    "navy", "maroon", "lime", "olive", "teal", "aqua",
    "blanc", "noir", "marron", "brun", "bleu", "rouge", "rose", 
    "vert", "gris", "jaune", "violet", "beige", "dor√©", "argent", "kaki",
    "turquoise", "fuchsia", "lavande", "ocre", "ivory", "ivoires", "argent√©",
    "rose gold", "off white", "peach pink", "sepia black", "golden",
    "sable", "chocolat", "prune" ,"dark brown"
]

mapping_couleurs = {
    "white": "Blanc",
    "off white": "Blanc cass√©",
    "ivory": "Blanc cass√©",
    "blanc": "Blanc",
    "dark brown": "Marron",
    "black": "Noir",
    "noir": "Noir",
    "sepia black": "Noir",
    
    "brown": "Marron",
    "brun": "Marron",
    "marron": "Marron",
    "chocolat": "Marron",
    
    "red": "Rouge",
    "rouge": "Rouge",
    
    "pink": "Rose",
    "rose": "Rose",
    "peach pink": "Rose",
    
    "green": "Vert",
    "vert": "Vert",
    "leaf green": "Vert",
    
    "grey": "Gris",
    "gray": "Gris",
    "gris": "Gris",
    "mirage grey": "Gris",
    
    "yellow": "Jaune",
    "jaune": "Jaune",
    
    "orange": "Orange",
    
    "purple": "Violet",
    "violet": "Violet",
    "lavande": "Violet",
    "prune": "Violet",
    
    "beige": "Beige",
    "sable": "Beige",
    "taupe": "Taupe",
    
    "gold": "Dor√©",
    "golden": "Dor√©",
    "rose gold": "Rose Gold",
    
    "silver": "Argent",
    "argent": "Argent",
    "argent√©": "Argent",
    
    "kaki": "Kaki",
    
    "fuchsia": "Fuchsia",
    "magenta": "Fuchsia",
    
    "blue": "Bleu",
    "bleu": "Bleu",
    "navy": "Bleu marine",
    "cyan": "Cyan",
    "aqua": "Cyan",
    "turquoise": "Turquoise",
    
    "maroon": "Bordeaux",
    "bordeaux": "Bordeaux",
    
    "lime": "Vert clair",
    "olive": "Vert olive",
    
    "teal": "Bleu-vert"
}



############################################
# Fonctions de transformation du CSV
############################################

def renommer_colonnes_pour_woocommerce(df):
    correspondance_woocommerce = {
        "R√©f√©rence": "SKU",
        "Nom de l'article (en Fran√ßais)": "Name",
        "Description courte (en Fran√ßais)": "Short description",
        "Description (en Fran√ßais)": "Description",
        "Prix pour le groupe D√©faut": "Regular price",
        "Stock - Quantit√©": "Stock",
        "Option Couleur (en Fran√ßais)": "Attribute 1 value(s)",
        "Option Taille (en Fran√ßais)": "Attribute 2 value(s)",
        "Poids (en Kg)": "Weight (kg)",
        "Longueur (en cm)": "Length (cm)",
        "Largeur (en cm)": "Width (cm)",
        "Hauteur (en cm)": "Height (cm)",
        "Cat√©gories": "Categories",
        "Parent": "Parent",
        "Images": "Images",
        "Garantie": "Warranty",
        "Pays de fabrication": "Country of manufacture",
        "Marque": "Brands"
    }
    df.rename(columns=correspondance_woocommerce, inplace=True)
    return df

def supprimer_doublons_colonnes(df):
    correspondance_woocommerce = {
        "R√©f√©rence": "SKU",
        "Nom de l'article (en Fran√ßais)": "Name",
        "Description courte (en Fran√ßais)": "Short description",
        "Description (en Fran√ßais)": "Description",
        "Prix pour le groupe D√©faut": "Regular price",
        "Prix de vente conseill√©": "Sale price",
        "Stock - Quantit√©": "Stock",
        "Option Couleur (en Fran√ßais)": "Attribute 1 value(s)",
        "Option Taille (en Fran√ßais)": "Attribute 2 value(s)",
        "Poids (en Kg)": "Weight (kg)",
        "Longueur (en cm)": "Length (cm)",
        "Largeur (en cm)": "Width (cm)",
        "Hauteur (en cm)": "Height (cm)",
        "Cat√©gories": "Categories",
        "Parent": "Parent",
        "Images": "Images",
        "Garantie": "Warranty",
        "Pays de fabrication": "Country of manufacture",
        "Marque": "Brands"
    }
    colonnes_presentes = df.columns
    colonnes_a_supprimer = [
        fr_col for fr_col, en_col in correspondance_woocommerce.items() 
        if fr_col in colonnes_presentes and en_col in colonnes_presentes
    ]
    df.drop(columns=colonnes_a_supprimer, inplace=True, errors='ignore')
    return df

def ajuster_categories(df):
    colonnes_categories = [
        'Nom de la cat√©gorie de niveau 1 (en Fran√ßais)',
        'Nom de la cat√©gorie de niveau 2 (en Fran√ßais)',
        'Nom de la cat√©gorie de niveau 3 (en Fran√ßais)',
        'Nom de la cat√©gorie de niveau 4 (en Fran√ßais)',
    ]
    colonnes_existantes = [col for col in colonnes_categories if col in df.columns]
    if colonnes_existantes:
        df['Categories'] = df[colonnes_existantes].apply(lambda x: ' > '.join(x.dropna()), axis=1)
    if 'Cat√©gorie principale du produit' in df.columns:
        df['Categories'] = df.apply(
            lambda x: f"{x['Categories']} | {x['Cat√©gorie principale du produit']}" 
            if pd.notnull(x['Cat√©gorie principale du produit']) else x['Categories'],
            axis=1
        )
    df.drop(columns=colonnes_existantes + ['Cat√©gorie principale du produit'], inplace=True, errors='ignore')
    return df

def formatter_images(df, taille_lot=100):
    base_url = "https://dev.yolobaby.online/wp-content/uploads/image-site/"
    
    colonnes_images = [
        "Image principale",
        "Image suppl√©mentaire n¬∞1",
        "Image suppl√©mentaire n¬∞2",
        "Image suppl√©mentaire n¬∞3",
        "Image suppl√©mentaire n¬∞4",
        "Image suppl√©mentaire n¬∞5",
        "Image suppl√©mentaire n¬∞6",
        "Image suppl√©mentaire n¬∞7",
        "Image suppl√©mentaire n¬∞8",
        "Image suppl√©mentaire n¬∞9"
    ]
    
    colonnes_existantes = [col for col in colonnes_images if col in df.columns]

    if not colonnes_existantes:
        print("‚ö†Ô∏è Aucune colonne d'image trouv√©e.")
        return df

    # Fusion des URLs compl√®tes dans une nouvelle colonne temporaire
    df["all_image_urls"] = df[colonnes_existantes].apply(
        lambda row: [base_url + img.strip() for img in row.dropna().astype(str)], axis=1
    )

    # G√©n√©ration directe de la colonne "Images"
    df["Images"] = df["all_image_urls"].apply(lambda urls: ", ".join(urls))

    # --- üëá Partie d√©sactiv√©e : r√©cup√©ration des IDs depuis l‚ÄôAPI + images suppl√©mentaires ---

    # Cr√©er une liste unique de toutes les URLs pour minimiser les appels API
    # toutes_urls = list(set(url for sublist in df["all_image_urls"] for url in sublist))

    # R√©cup√©rer les IDs en batch depuis l'API
    # url_to_id = recuperer_id_images_wp_via_api_batch(toutes_urls, taille_lot)

    # Associer les IDs r√©cup√©r√©s aux URLs dans le DataFrame
    # def generer_meta(row):
    #     urls_sup = row["all_image_urls"][1:]  # images suppl√©mentaires uniquement
    #     ids_sup = [str(url_to_id[url]) for url in urls_sup if url in url_to_id]
    #     return ",".join(ids_sup)

    # df["_wc_additional_variation_images"] = df.apply(generer_meta, axis=1)

    # --- ‚òùÔ∏è Fin de la partie d√©sactiv√©e ---

    # Nettoyage
    df.drop(
        columns=colonnes_existantes + ["all_image_urls"], inplace=True, errors="ignore"
    )

    return df


# --- üëá Fonction API d√©sactiv√©e mais conserv√©e si besoin futur ---
# def recuperer_id_images_wp_via_api_batch(urls, taille_lot=100):
#     api_url = "https://dev.yolobaby.online/api-images.php"
#     url_to_id = {}

#     for i in range(0, len(urls), taille_lot):
#         lot_urls = urls[i : i + taille_lot]
#         try:
#             response = requests.post(
#                 api_url, json={"urls": lot_urls, "api_key": "12345"}
#             )
#             response.raise_for_status()
#             resultat = response.json()
#             url_to_id.update(resultat)
#             print(
#                 f"‚úÖ Lot {i // taille_lot + 1}/{(len(urls) - 1) // taille_lot + 1} trait√© avec succ√®s."
#             )
#         except requests.RequestException as e:
#             print(f"‚ùå Erreur API sur le lot {i // taille_lot + 1}: {e}")
#             print(f"R√©ponse re√ßue : {response.text}")
#             sleep(1)  # Pause en cas d'erreur pour √©viter surcharge API

#     return url_to_id

#
############################################
# Fonctions de d√©tection/extraction des couleurs
############################################

def detecter_toutes_couleurs(nom_produit: str):
    if not isinstance(nom_produit, str):
        return []
    
    tokens = re.split(r"[\s\-\|\(\),/]+", nom_produit.lower())
    trouvees = [mapping_couleurs[t] for t in tokens if t in mapping_couleurs]

    return list(dict.fromkeys(trouvees))  # Supprime les doublons

# üìå Fonction pour normaliser une liste de couleurs
def normaliser_liste_couleurs(couleurs_brutes: list):
    if not couleurs_brutes:
        return ""
    return ", ".join(dict.fromkeys([mapping_couleurs.get(c.lower(), "Non sp√©cifi√©e").title() for c in couleurs_brutes]))

# üìå Fonction pour nettoyer le nom du produit en supprimant la couleur
def nettoyer_nom_produit(nom_produit: str, couleurs: list):
    if not isinstance(nom_produit, str):
        return nom_produit
    # On retire d'abord les couleurs (s'il y en a) en tant que mots entiers
    for couleur in couleurs:
        nom_produit = re.sub(rf"\b{couleur}\b", "", nom_produit, flags=re.IGNORECASE)
    # Puis, si le nom contient " - ", on prend uniquement la partie avant
    if " - " in nom_produit:
        nom_produit = nom_produit.split(" - ")[0]
    # Enfin, on nettoie les espaces superflus et d'√©ventuels tirets en fin de cha√Æne
    nom_produit = re.sub(r'[-\s]+$', '', nom_produit)
    return re.sub(r'\s+', ' ', nom_produit).strip()

# üìå Fonction pour d√©tecter les produits composites
def extraire_couleurs_composite(nom_produit: str):
    """
    Extrait les couleurs li√©es aux √©l√©ments "Ch√¢ssis" et "Si√®ge".
    Un produit est consid√©r√© composite s'il a **Ch√¢ssis** et **Si√®ge** dans le m√™me nom.
    """

    if not isinstance(nom_produit, str):
        return {}

    # Normalisation du texte (supprimer accents et mettre en minuscule)
    nom_lower = unicodedata.normalize("NFKD", nom_produit).encode("ASCII", "ignore").decode("utf-8").lower()
    resultat = {}

    # D√©finition des √©l√©ments √† rechercher
    elements_couleur = {
        "Ch√¢ssis": ["ch√¢ssis", "chassis"],
        "Si√®ge": ["si√®ge", "siege", "assise"]
    }

    # V√©rification de la pr√©sence des deux termes dans le m√™me nom de produit
    contient_chassis = any(mot in nom_lower for mot in elements_couleur["Ch√¢ssis"])
    contient_siege = any(mot in nom_lower for mot in elements_couleur["Si√®ge"])

    if not (contient_chassis and contient_siege):
        return {}  # Pas un produit composite

    # D√©finition des adjectifs ignor√©s
    adjectifs_ignores = [
    "light", "pale", "deep", "bright", "medium",
    "fonce", "fonc√©", "clair", "p√¢le", "flashy", "fluorescent",
    "cozy", "mirage", "sepia", "peach", "magic", "canvas", "navy"
    "fog", "stormy", "almond", "leaf", "navy","candy", "fog", "almond", "canvas"
    
    # Ajout des adjectifs li√©s au Ch√¢ssis
    "chrome", "matt", "matt√©", "brillant", "argent√©", "dark", "magic"
    ]

    # Recherche des couleurs pour chaque √©l√©ment
    for nom_element, variantes in elements_couleur.items():
        for variante in variantes:
            # Correction du regex pour √©viter l'erreur "no such group"
            regex_patterns = [
                rf"{variante}\s+(?:({'|'.join(adjectifs_ignores)})\s+)?({'|'.join(couleurs_base)})",
                rf"({'|'.join(couleurs_base)})\s+{variante}"
            ]
            for regex in regex_patterns:
                match = re.search(regex, nom_lower, re.IGNORECASE)
                if match:
                    # V√©rification si l'adjectif est captur√©
                    couleur_brute = match.group(2) if match.lastindex == 2 else match.group(1)
                    couleur_normalisee = mapping_couleurs.get(couleur_brute, couleur_brute).title()
                    resultat[nom_element] = couleur_normalisee
                    break  # Sortir d√®s qu'une couleur est trouv√©e

    return resultat

  # Renvoie un dictionnaire contenant les couleurs d√©tect√©es
def determiner_si_variable(nom_produit: str, option_taille: str = ""):
    """
    Un produit est variable s‚Äôil :
    - contient exactement une couleur d√©tect√©e dans son nom
    - ou s‚Äôil a une taille d√©tect√©e via un pattern intelligent
    """
    couleurs_detectees = detecter_toutes_couleurs(nom_produit)

    # S√©curisation max ici üëá
    taille = str(option_taille).strip().lower() if pd.notnull(option_taille) else ""

    contient_taille = bool(re.search(r"(mois|ans|m|t)", taille)) and len(taille) <= 10

    return len(couleurs_detectees) == 1 or contient_taille



# üìå Fonction pour regrouper les produits **variables** par couleur


def regrouper_variations_par_couleur(df):
    """
    Regroupe les produits par mod√®le (bas√© sur le nom nettoy√© sans couleur).

    - M√™me s‚Äôil n‚Äôy a qu‚Äôun seul produit avec une couleur, on le traite comme un produit variable
      avec une seule variation.
    """
    # 1) Regrouper par nom nettoy√© (sans couleur)
    groupes = {}
    for _, row in df.iterrows():
        nom_original = str(row["Name"])
        couleurs_detectees = detecter_toutes_couleurs(nom_original)
        nom_sans_couleur = nettoyer_nom_produit(nom_original, couleurs_detectees).strip()
        key = nom_sans_couleur.lower()
        groupes.setdefault(key, []).append(row)
    
    liste_resultats = []

    # 2) Traiter chaque groupe
    for key, rows in groupes.items():
        couleurs_group = set()
        for row in rows:
            couleurs = detecter_toutes_couleurs(str(row["Name"]))
            couleurs_group.update(couleurs)
        couleurs_group_list = list(couleurs_group)

        # ‚úÖ Cas 1 : groupe avec un seul produit mais une couleur d√©tect√©e ‚Üí variable avec 1 variation
        if len(rows) == 1 and len(couleurs_group_list) == 1:
            row = rows[0]
            parent = row.copy()
            variation = row.copy()

            sku_orig = str(row["SKU"])
            parent["SKU"] = "PARENT-" + sku_orig
            parent["Name"] = nettoyer_nom_produit(row["Name"], couleurs_group_list).strip()
            parent["Type"] = "variable"
            parent["Attribute 1 name"] = "Couleur"
            parent["Attribute 1 value(s"] = normaliser_liste_couleurs(couleurs_group_list)
            parent["Attribute 1 visible"] = "yes"
            parent["Attribute 1 global"] = "yes"
            parent["Code EAN"] = ""
            parent["Parent SKU"] = ""
            liste_resultats.append(parent)

            variation["Type"] = "variation"
            variation["Parent SKU"] = parent["SKU"]
            variation["Attribute 1 name"] = "Couleur"
            variation["Attribute 1 value(s"] = normaliser_liste_couleurs(couleurs_group_list)
            variation["Attribute 1 visible"] = "yes"
            variation["Attribute 1 global"] = "yes"
            variation["SKU"] = sku_orig + "-V1"  # suffixe pour unicit√©
            liste_resultats.append(variation)

        # ‚úÖ Cas 2 : plusieurs produits ‚Üí produit variable avec variations multiples
        elif len(rows) > 1:
            parent = rows[0].copy()
            sku_orig = str(parent["SKU"])
            parent["SKU"] = "PARENT-" + sku_orig
            parent["Name"] = nettoyer_nom_produit(parent["Name"], detecter_toutes_couleurs(parent["Name"])).strip()
            parent["Type"] = "variable"
            parent["Attribute 1 name"] = "Couleur"
            parent["Attribute 1 value(s"] = normaliser_liste_couleurs(couleurs_group_list)
            parent["Attribute 1 visible"] = "yes"
            parent["Attribute 1 global"] = "yes"
            parent["Code EAN"] = ""
            parent["Parent SKU"] = ""
            liste_resultats.append(parent)

            for row in rows:
                variation = row.copy()
                variation["Type"] = "variation"
                variation["Parent SKU"] = parent["SKU"]
                var_couleurs = detecter_toutes_couleurs(str(variation["Name"]))
                variation["Attribute 1 name"] = "Couleur"
                variation["Attribute 1 value(s"] = normaliser_liste_couleurs(var_couleurs)
                variation["Attribute 1 visible"] = "yes"
                variation["Attribute 1 global"] = "yes"
                if str(variation["SKU"]) == sku_orig:
                    suffix = var_couleurs[0][:2].upper() if var_couleurs else "XX"
                    variation["SKU"] = sku_orig + suffix
                liste_resultats.append(variation)

        # ‚ùå Cas inattendu (aucune couleur trouv√©e ou vide)
        else:
            print(f"‚ÑπÔ∏è Groupe ignor√© (pas de couleur d√©tect√©e) : {key}")

    df_final = pd.DataFrame(liste_resultats)
    return df_final


def regrouper_variations_par_taille(df):
    """
    Regroupe les produits variables par taille.
    """
    groupes = {}

    for _, row in df.iterrows():
        nom_original = str(row["Name"])
        taille_raw = row.get("Attribute 2 value(s)", "")
        taille = str(taille_raw).strip() if pd.notnull(taille_raw) else ""
        nom_base = re.sub(rf"\b{re.escape(taille)}\b", "", nom_original, flags=re.IGNORECASE).strip()
        groupes.setdefault(nom_base.lower(), []).append(row)

    liste_resultats = []

    for ref, rows in groupes.items():
        tailles_group = set()
        for row in rows:
            taille_raw = row.get("Attribute 2 value(s)", "")
            taille = str(taille_raw).strip() if pd.notnull(taille_raw) else ""
            if taille:
                tailles_group.add(taille)
        tailles_group_list = sorted(list(tailles_group))

        parent = rows[0].copy()
        sku_orig = str(parent["SKU"]).strip()
        parent["SKU"] = "PARENT-" + sku_orig
        parent["Type"] = "variable"
        parent["Attribute 2 name"] = "Taille"
        parent["Attribute 2 value(s)"] = ", ".join(tailles_group_list)
        parent["Attribute 2 visible"] = "yes"
        parent["Attribute 2 global"] = "yes"
        parent["Parent SKU"] = ""
        if "EAN" in parent:
            parent["EAN"] = ""
        elif "Code EAN" in parent:
            parent["Code EAN"] = ""
        liste_resultats.append(parent)

        for row in rows:
            variation = row.copy()
            variation["Type"] = "variation"
            variation["Parent SKU"] = parent["SKU"]
            variation["Attribute 2 name"] = "Taille"
            taille_raw = variation.get("Attribute 2 value(s)", "")
            taille = str(taille_raw).strip() if pd.notnull(taille_raw) else ""
            variation["Attribute 2 value(s)"] = taille
            variation["Attribute 2 visible"] = "yes"
            variation["Attribute 2 global"] = "yes"

            if str(variation["SKU"]).strip() == sku_orig:
                suffix = taille[:2].upper() if taille else "XX"
                variation["SKU"] = sku_orig + suffix

            liste_resultats.append(variation)

    return pd.DataFrame(liste_resultats)


def main():
    root = Tk()
    root.withdraw()

    # üìÇ S√©lection du fichier CSV
    chemin_fichier = filedialog.askopenfilename(
        filetypes=[("CSV Files", "*.csv")],
        title="S√©lectionnez le fichier CSV"
    )
    if not chemin_fichier:
        print("‚ùå Aucun fichier s√©lectionn√©. Fermeture du script.")
        return

    try:
        # Chargement du fichier avec encodage UTF-8
        df = pd.read_csv(chemin_fichier, encoding="utf-8-sig", dtype=str)
        print(f"üìÇ Fichier charg√© : {os.path.basename(chemin_fichier)}")

        df.columns = df.columns.str.strip()
        print("üîç Colonnes d√©tect√©es :", df.columns.tolist())

        df = renommer_colonnes_pour_woocommerce(df)
        print("‚úÖ Colonnes apr√®s renommage :", df.columns.tolist())

        if "Name" not in df.columns:
            raise KeyError(f"‚ùå La colonne 'Name' est absente apr√®s transformation ! Colonnes actuelles : {df.columns.tolist()}")

        # S'assurer que la colonne "Attribute 2 value(s)" existe
        if "Attribute 2 value(s)" not in df.columns:
            df["Attribute 2 value(s)"] = ""

        # üí• Forcer la colonne √† √™tre du texte nettoy√©
        df["Attribute 2 value(s)"] = df["Attribute 2 value(s)"].fillna("").astype(str).apply(str.strip)

        df = supprimer_doublons_colonnes(df)
        print("‚úÖ Colonnes apr√®s suppression des doublons :", df.columns.tolist())

        df = ajuster_categories(df)
        df = formatter_images(df, taille_lot=50)

        # D√©tection des produits composites et d√©finition du type
        df["Composants composites (encod√©s en JSON)"] = df["Name"].apply(extraire_couleurs_composite)
        df["Type"] = df["Composants composites (encod√©s en JSON)"].apply(
            lambda x: "composite" if len(x) > 0 else "variable"
        )

        # S√©paration entre produits composites et produits variables
        df_composites = df[df["Type"] == "composite"]
        df_variables = df[df["Type"] == "variable"]

        print(f"üõ†Ô∏è Produits composites d√©tect√©s : {len(df_composites)}")
        print(f"üõ†Ô∏è Produits variables d√©tect√©s : {len(df_variables)}")

        # ‚úÖ Marquage avec protection contre NaN
        df_variables["Is_Variable"] = df_variables.apply(
            lambda row: determiner_si_variable(
                str(row["Name"]),
                str(row.get("Attribute 2 value(s)", "")).strip() if pd.notnull(row.get("Attribute 2 value(s)")) else ""
            ),
            axis=1
        )

        df_variables_reels = df_variables[df_variables["Is_Variable"]]
        print(f"‚úÖ Produits variables r√©ellement √©ligibles : {len(df_variables_reels)}")

        # S√©paration selon la pr√©sence d'une option taille dans "Attribute 2 value(s)"
        df_has_size = df_variables_reels[
            df_variables_reels["Attribute 2 value(s)"].notna() & 
            (df_variables_reels["Attribute 2 value(s)"].str.strip() != "")
        ]
        df_without_size = df_variables_reels[
            df_variables_reels["Attribute 2 value(s)"].isna() | 
            (df_variables_reels["Attribute 2 value(s)"].str.strip() == "")
        ]

        # Traitement des produits variables dot√©s d'une option taille (regroupement par taille)
        if not df_has_size.empty:
            df_grouped_size = regrouper_variations_par_taille(df_has_size)
            print(f"‚úÖ Produits variables regroup√©s par taille : {len(df_grouped_size)}")
        else:
            df_grouped_size = pd.DataFrame()
            print("‚ÑπÔ∏è Aucun produit avec option taille d√©tect√©.")

        # Traitement des produits variables sans option taille (regroupement par couleur)
        if not df_without_size.empty:
            df_grouped_color = regrouper_variations_par_couleur(df_without_size)
            print(f"‚úÖ Produits variables regroup√©s par couleur : {len(df_grouped_color)}")
        else:
            df_grouped_color = pd.DataFrame()
            print("‚ÑπÔ∏è Aucun produit sans option taille d√©tect√©, regroupement couleur non n√©cessaire.")

        # Fusion de tous les produits finaux (composites, variables par taille et par couleur)
        df_final = pd.concat([df_composites, df_grouped_size, df_grouped_color], ignore_index=True)

        # Export du fichier final
        nouveau_chemin = os.path.splitext(chemin_fichier)[0] + "_final.csv"
        df_final.to_csv(nouveau_chemin, index=False, sep=",", encoding="utf-8-sig")
        print(f"‚úÖ Fichier final export√© avec toutes les donn√©es : {nouveau_chemin}")

    except Exception as e:
        print(f"‚ùå Erreur pendant le traitement : {e}")

if __name__ == "__main__":
    main()
